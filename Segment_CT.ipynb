{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segment_CT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq7hvLoj2_r4"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8kLdYYeUZcF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Wtm53bG7xW"
      },
      "source": [
        "%cd\n",
        "import os\n",
        "!git clone --quiet https://github.com/rvignav/Mask_RCNN.git\n",
        "if not os.path.isdir('../logs'):\n",
        "  os.mkdir('../logs')\n",
        "!cp -r '/content/drive/My Drive/lesion' '../logs/lesion'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZY2h5buS9xb"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "\n",
        "!pip install -q PyDrive\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SVHFnl5Hwe3"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "\n",
        "!cp ~/Mask_RCNN/samples/balloon/balloon.py ./lesion.py\n",
        "\n",
        "!sed -i -- 's/balloon/lesion/g' lesion.py\n",
        "!sed -i -- 's/Balloon/Lesion/g' lesion.py\n",
        "!sed -i -- 's/epochs=30/epochs=100/g' lesion.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJGrimv2Xuf3"
      },
      "source": [
        "%cd ~/Mask_RCNN\n",
        "\n",
        "# !python lesion.py train --dataset='/content/drive/My Drive/images2/' --weights=last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o7dH-mRX2A0"
      },
      "source": [
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import skimage\n",
        "import glob\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "# from google.colab import files\n",
        "\n",
        "import lesion\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "\n",
        "custom_WEIGHTS_PATH = sorted(glob.glob(\"/logs/*/mask_rcnn_*.h5\"))[-1]\n",
        "# files.download(custom_WEIGHTS_PATH)\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "config = lesion.LesionConfig()\n",
        "custom_DIR = os.path.join(ROOT_DIR, '/content/drive/My Drive/images2/')\n",
        "\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "# Device to load the neural network on.\n",
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\"\n",
        "\n",
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax\n",
        "  \n",
        "# Load validation dataset\n",
        "dataset = lesion.LesionDataset()\n",
        "dataset.load_lesion(custom_DIR, \"val\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
        "\n",
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)\n",
        "\n",
        "# load the last model you trained\n",
        "# weights_path = model.find_last()[1]\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", custom_WEIGHTS_PATH)\n",
        "model.load_weights(custom_WEIGHTS_PATH, by_name=True)\n",
        "\n",
        "from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n",
        "reload(visualize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DTQQshuKTBl"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def flatten(seq):\n",
        "  for el in seq:\n",
        "    if isinstance(el, list):\n",
        "      yield from flatten(el)\n",
        "    else:\n",
        "      yield el\n",
        "\n",
        "dices = []\n",
        "\n",
        "for i in range(2):\n",
        "  AMOUNT = 0 #212-45\n",
        "  image_id = dataset.image_ids[i]\n",
        "  all_points = []\n",
        "  f = open('/content/drive/My Drive/images2/val' + str(i) + '.txt', 'r')\n",
        "  l = f.read().replace(\"[\", \"\").replace(\"]\", \"\").split(\"), \")\n",
        "\n",
        "  minArr = 100000000\n",
        "  for item in l:\n",
        "    t = item[1:].split(\", \")\n",
        "    if (int(t[0]) < minArr):\n",
        "      minArr = int(t[0])\n",
        "  \n",
        "  minAll = 10000000\n",
        "  for item in l:\n",
        "    t = item[1:].split(\", \")\n",
        "    if ')' in t[1]:\n",
        "      t[1] = t[1][0:len(t[1])-1]\n",
        "    new_tup = (int(t[1]), -1 * int(t[0]))\n",
        "    if (-1 * int(t[0]) < minAll):\n",
        "      minAll = -1 * int(t[0])\n",
        "    if new_tup not in all_points:\n",
        "      all_points.append(new_tup)\n",
        "\n",
        "  for i in range(len(all_points)):\n",
        "    all_points[i] = (all_points[i][0], all_points[i][1] + (minArr - minAll))\n",
        "\n",
        "  image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "      modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "  info = dataset.image_info[image_id]\n",
        "  results = model.detect([image], verbose=1)\n",
        "  r = results[0]\n",
        "\n",
        "  masked = r['masks']\n",
        "\n",
        "  fig=plt.figure()\n",
        "  ax2=fig.add_axes([0,0,1,1])\n",
        "\n",
        "  xArr = []\n",
        "  yArr = []\n",
        "  for idx in range(masked.shape[2]):\n",
        "    array = masked[:,:,idx]\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(len(array)):\n",
        "        for j in range(len(array[0])):\n",
        "            if array[i][j] == True:\n",
        "                xs.append(j)\n",
        "                ys.append(i)\n",
        "    xArr.append(xs)\n",
        "    yArr.append(ys)\n",
        "\n",
        "  m = max(flatten(yArr)) + min(flatten(yArr))\n",
        "  for i in range(len(yArr)):\n",
        "    ys = yArr[i]\n",
        "    for j in range(len(ys)):\n",
        "      ys[j] = m - ys[j]\n",
        "    yArr[i] = ys\n",
        "  \n",
        "  all_masks = []\n",
        "  for i in range(len(xArr)):\n",
        "    for j in range(len(xArr[i])):\n",
        "      tup = (xArr[i][j], yArr[i][j])\n",
        "      if tup not in all_masks: \n",
        "        all_masks.append(tup)\n",
        "  \n",
        "  xp = []\n",
        "  yp = []\n",
        "\n",
        "  for i in range(len(all_points)):\n",
        "    tup = all_points[i]\n",
        "    tup = (tup[0], tup[1] + AMOUNT)\n",
        "    all_points[i] = tup\n",
        "\n",
        "  for tup in all_points:\n",
        "    xp.append(tup[0])\n",
        "    yp.append(tup[1])\n",
        "  \n",
        "  ax2.scatter(xp, yp, color=str('g'))\n",
        "\n",
        "  for i in range(len(xArr)):\n",
        "    xs = xArr[i]\n",
        "    ys = yArr[i]\n",
        "    ax2.scatter(xs, ys, color=str('b'))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  over = 0\n",
        "  for tup in all_masks:\n",
        "    if tup in all_points:\n",
        "      over += 1\n",
        "  tot = len(all_points) + len(all_masks) - over\n",
        "  dices.append(float(over)/tot)\n",
        "  print(\"Individual DICE Score: \" + str(float(over)/tot))\n",
        "\n",
        "dice_coeff = sum(dices) / len(dices)\n",
        "print(\"Overall DICE Coefficient: \" + str(dice_coeff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soLYgCbS37Tp"
      },
      "source": [
        "for i in range(2):\n",
        "  image_id = dataset.image_ids[i]\n",
        "  image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "      modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "  info = dataset.image_info[image_id]\n",
        "  results = model.detect([image], verbose=1)\n",
        "  ax = get_ax(1)\n",
        "  r = results[0]\n",
        "\n",
        "  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                              dataset.class_names, r['scores'], ax=ax,\n",
        "                              title=\"Predictions\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}